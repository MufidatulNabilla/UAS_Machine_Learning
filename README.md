# Proyek Analisis Sentimen ğŸŒŸ

Selamat datang di proyek **Analisis Sentimen Ulasan Universal Studios**! ğŸ¢ğŸ¡ Repositori ini menerapkan model deep learning canggih untuk mengklasifikasikan ulasan pengunjung ke dalam sentimen: Positif, Netral, atau Negatif.

---

## âœ¨ Sorotan Proyek
1. **Dataset**: Ulasan pengunjung dari Universal Studios ğŸ™ï¸, tersedia di Kaggle [di sini](https://www.kaggle.com/datasets/dwiknrd/reviewuniversalstudio).
2. **Model yang Digunakan**:
   - **LSTM** (Long Short-Term Memory): Memahami pola berurutan dalam data teks atau angka.
   - **BERT** (Bidirectional Encoder Representations from Transformers): Memanfaatkan embedding kontekstual untuk klasifikasi teks yang mutakhir.
3. **Tujuan**:
   - Melakukan analisis sentimen.
   - Membandingkan kinerja model.

---

## ğŸ“š Alur Kerja

### 1ï¸âƒ£ Persiapan Dataset
- **Sumber**: Dataset Ulasan Universal Studios.
- **Langkah Pra-pemrosesan**:
  - Menghapus URL, mention, hashtag, dan emoji.
  - Tokenisasi dan pembersihan teks.
  - Menerapkan stemming dan lemmatization.

### 2ï¸âƒ£ Analisis Data Eksploratif (EDA)
- Visualisasi:
  - Distribusi penilaian ğŸ“Š
  - Distribusi sentimen ğŸŸ¢ğŸŸ¡ğŸ”´
  - Word cloud ulasan ğŸŒ¥ï¸
  - Tren di berbagai cabang dan tanggal ğŸ“ˆ

### 3ï¸âƒ£ Pendekatan Pemodelan

#### A. Model LSTM
- **Arsitektur**:
  - Tokenisasi dan padding.
  - Lapisan Embedding.
  - Lapisan LSTM Bidirectional.
  - Lapisan Dense yang Terhubung Penuh.
- **Pelatihan**:
  - Ukuran batch: 32, Epoch: 15.
  - Dioptimalkan untuk panjang urutan dan ukuran batch.
- **Kinerja**:
  - Metrik: Akurasi, Presisi, Recall.

#### B. Model BERT
- **Proses**:
  - Tokenisasi teks menggunakan `BertTokenizer`.
  - Encoding label menggunakan `LabelEncoder`.
  - Fine-tuning `TFBertForSequenceClassification` yang sudah dilatih sebelumnya.
- **Pelatihan**:
  - Ukuran batch: 64, Epoch: 10.
  - Dioptimalkan dengan `AdamWeightDecay`.
- **Evaluasi**:
  - Confusion Matrix ğŸ“Š
  - Laporan Klasifikasi ğŸ“‹

---

## ğŸ” Visualisasi
- **Perkembangan Pelatihan**:
  - Tren Akurasi dan Loss per epoch untuk kedua model.
- **Confusion Matrix**:
  - Ditampilkan dengan heatmap untuk evaluasi yang jelas.

---

## ğŸ› ï¸ Persiapan dan Instalasi
1. Clone repositori:
   ```bash
   git clone <repository-url>
   ```
2. Instal pustaka yang diperlukan:
   ```bash
   pip install -r requirements.txt
   ```
3. Muat dataset dari Kaggle:
   ```bash
   kaggle datasets download -d dwiknrd/reviewuniversalstudio
   ```

---

## ğŸš€ Hasil
- **Model LSTM**: Menunjukkan kinerja yang tangguh dengan data sekuensial.
- **Model BERT**: Mencapai akurasi dan presisi yang unggul melalui pemahaman kontekstual.

---

## ğŸ™Œ Kontribusi
Silakan ajukan isu atau berkontribusi dengan mengirimkan pull request! Mari kita tingkatkan analisis sentimen bersama. ğŸŒŸ

---

## ğŸ“§ Kontak
Untuk pertanyaan, hubungi [your-email@example.com].

